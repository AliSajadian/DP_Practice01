{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDyUBglYmaO8FffUNGHX1P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliSajadian/DP_Practice01/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SO8gWl8NZfyC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuxO7t2XblJG",
        "outputId": "eb40c933-d234-46fe-d382-1b841e7a54ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO39WvmpbyHR",
        "outputId": "48865a17-47ed-49a5-c44d-8f1c37e1d1df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ZFOHjUcCyG",
        "outputId": "269b89a4-3a70-4039-e4ff-5c81c4a99775"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 4510\n",
        "print(train_labels[i])\n",
        "plt.gray()\n",
        "plt.imshow(train_features[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "1HxzQuRccUhK",
        "outputId": "9afeb95e-f924-43ec-bad4-75b946946a85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7dbec18ce050>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "XfJDbjbwdjOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.min(train_features[i]), np.max(train_features[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPFx3PHHdh6D",
        "outputId": "7a30624c-e5df-4f82-b02a-01da84e58e01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_features / 255.0\n",
        "test_features = test_features / 255.0"
      ],
      "metadata": {
        "id": "lPmAzSZMcg0y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition"
      ],
      "metadata": {
        "id": "Ym8sT9SagkCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "metadata": {
        "id": "LH203sW0gjI9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "niiPxWYrjDBf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 28, 28))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZWfywi9jeF_",
        "outputId": "b2bd8415-6e19-4e8e-f668-ec8c94666eff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 118282 (462.04 KB)\n",
            "Trainable params: 118282 (462.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train_features, train_labels, epochs=500, batch_size=256, validation_data=(test_features, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvxjx3z_k08I",
        "outputId": "ecf48319-4718-44e1-fb58-b6996c0ca1a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.7689e-06 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9821\n",
            "Epoch 2/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.6113e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9820\n",
            "Epoch 3/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.4760e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9822\n",
            "Epoch 4/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3541e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9822\n",
            "Epoch 5/500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.2469e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9822\n",
            "Epoch 6/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.1467e-06 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9822\n",
            "Epoch 7/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.0547e-06 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9820\n",
            "Epoch 8/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 9.7328e-07 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9819\n",
            "Epoch 9/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 8.9594e-07 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9820\n",
            "Epoch 10/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.2507e-07 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9821\n",
            "Epoch 11/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 7.6105e-07 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9821\n",
            "Epoch 12/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0047e-07 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9820\n",
            "Epoch 13/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.4536e-07 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9820\n",
            "Epoch 14/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.9449e-07 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9821\n",
            "Epoch 15/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.4854e-07 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9820\n",
            "Epoch 16/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.0515e-07 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9820\n",
            "Epoch 17/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.6293e-07 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9821\n",
            "Epoch 18/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.2672e-07 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9821\n",
            "Epoch 19/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 3.9191e-07 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9822\n",
            "Epoch 20/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 3.6020e-07 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9822\n",
            "Epoch 21/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 3.3151e-07 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9820\n",
            "Epoch 22/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 3.0407e-07 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9819\n",
            "Epoch 23/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.7818e-07 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9819\n",
            "Epoch 24/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.5518e-07 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9820\n",
            "Epoch 25/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 2.3423e-07 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9820\n",
            "Epoch 26/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 2.1462e-07 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9820\n",
            "Epoch 27/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.9720e-07 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9820\n",
            "Epoch 28/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.8048e-07 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9820\n",
            "Epoch 29/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.6549e-07 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9820\n",
            "Epoch 30/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.5107e-07 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9821\n",
            "Epoch 31/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 1.3845e-07 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9820\n",
            "Epoch 32/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.2655e-07 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9821\n",
            "Epoch 33/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.1590e-07 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9820\n",
            "Epoch 34/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.0601e-07 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9824\n",
            "Epoch 35/500\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 9.6764e-08 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9823\n",
            "Epoch 36/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 8.8638e-08 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9821\n",
            "Epoch 37/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.0720e-08 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9823\n",
            "Epoch 38/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 7.4033e-08 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9825\n",
            "Epoch 39/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.7291e-08 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9824\n",
            "Epoch 40/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 6.1534e-08 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9824\n",
            "Epoch 41/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.6012e-08 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9823\n",
            "Epoch 42/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.0996e-08 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9824\n",
            "Epoch 43/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.6412e-08 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9824\n",
            "Epoch 44/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.2393e-08 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9824\n",
            "Epoch 45/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 3.8614e-08 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9823\n",
            "Epoch 46/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 3.5208e-08 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9823\n",
            "Epoch 47/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.2099e-08 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9822\n",
            "Epoch 48/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.9383e-08 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9823\n",
            "Epoch 49/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 2.6762e-08 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9822\n",
            "Epoch 50/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.4515e-08 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9823\n",
            "Epoch 51/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 2.2205e-08 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9824\n",
            "Epoch 52/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 2.0216e-08 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9824\n",
            "Epoch 53/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.8565e-08 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9823\n",
            "Epoch 54/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.6872e-08 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9824\n",
            "Epoch 55/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.5432e-08 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9824\n",
            "Epoch 56/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.4112e-08 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9825\n",
            "Epoch 57/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.2865e-08 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9825\n",
            "Epoch 58/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.1724e-08 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9825\n",
            "Epoch 59/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.0671e-08 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9825\n",
            "Epoch 60/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 9.7970e-09 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9825\n",
            "Epoch 61/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 8.9347e-09 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9824\n",
            "Epoch 62/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 8.2235e-09 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9825\n",
            "Epoch 63/500\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 7.5003e-09 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9822\n",
            "Epoch 64/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 6.9181e-09 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9824\n",
            "Epoch 65/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 6.3419e-09 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9822\n",
            "Epoch 66/500\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 5.8015e-09 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9822\n",
            "Epoch 67/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.3624e-09 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9822\n",
            "Epoch 68/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9333e-09 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9822\n",
            "Epoch 69/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.5339e-09 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9822\n",
            "Epoch 70/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.1842e-09 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9822\n",
            "Epoch 71/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 3.9021e-09 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9821\n",
            "Epoch 72/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.5743e-09 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9821\n",
            "Epoch 73/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 3.2981e-09 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9821\n",
            "Epoch 74/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 3.0875e-09 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9822\n",
            "Epoch 75/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 2.8173e-09 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9822\n",
            "Epoch 76/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 2.6405e-09 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.9823\n",
            "Epoch 77/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 2.4756e-09 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9823\n",
            "Epoch 78/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 2.2968e-09 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9823\n",
            "Epoch 79/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.1835e-09 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9824\n",
            "Epoch 80/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.9948e-09 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 0.9824\n",
            "Epoch 81/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.9054e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9824\n",
            "Epoch 82/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.7742e-09 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9823\n",
            "Epoch 83/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.6590e-09 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9823\n",
            "Epoch 84/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.5477e-09 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9824\n",
            "Epoch 85/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4722e-09 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9824\n",
            "Epoch 86/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4007e-09 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9822\n",
            "Epoch 87/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3192e-09 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9823\n",
            "Epoch 88/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.2875e-09 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9823\n",
            "Epoch 89/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.1981e-09 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9823\n",
            "Epoch 90/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 1.1345e-09 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9822\n",
            "Epoch 91/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.0828e-09 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9822\n",
            "Epoch 92/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.0033e-09 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9821\n",
            "Epoch 93/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 9.7950e-10 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9820\n",
            "Epoch 94/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 9.4970e-10 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9820\n",
            "Epoch 95/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.7221e-10 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9820\n",
            "Epoch 96/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.4241e-10 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9819\n",
            "Epoch 97/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.1857e-10 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9820\n",
            "Epoch 98/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.7685e-10 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9820\n",
            "Epoch 99/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.5897e-10 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9820\n",
            "Epoch 100/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9820\n",
            "Epoch 101/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 7.2916e-10 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9820\n",
            "Epoch 102/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.7751e-10 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9820\n",
            "Epoch 103/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.8943e-10 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9820\n",
            "Epoch 104/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4770e-10 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9820\n",
            "Epoch 105/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3976e-10 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9820\n",
            "Epoch 106/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0995e-10 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9820\n",
            "Epoch 107/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.1591e-10 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9820\n",
            "Epoch 108/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9820\n",
            "Epoch 109/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.8413e-10 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9818\n",
            "Epoch 110/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.8810e-10 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9820\n",
            "Epoch 111/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.9803e-10 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9817\n",
            "Epoch 112/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.7817e-10 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9817\n",
            "Epoch 113/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.4240e-10 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9817\n",
            "Epoch 114/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.4836e-10 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9818\n",
            "Epoch 115/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.5035e-10 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9818\n",
            "Epoch 116/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.3843e-10 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9815\n",
            "Epoch 117/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2849e-10 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9816\n",
            "Epoch 118/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2651e-10 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9815\n",
            "Epoch 119/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5234e-10 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9814\n",
            "Epoch 120/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.4240e-10 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9815\n",
            "Epoch 121/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.2253e-10 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9817\n",
            "Epoch 122/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4042e-10 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9817\n",
            "Epoch 123/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2253e-10 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9818\n",
            "Epoch 124/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9818\n",
            "Epoch 125/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9818\n",
            "Epoch 126/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9818\n",
            "Epoch 127/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.0267e-10 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9818\n",
            "Epoch 128/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9816\n",
            "Epoch 129/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9817\n",
            "Epoch 130/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9817\n",
            "Epoch 131/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.0068e-10 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9817\n",
            "Epoch 132/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9817\n",
            "Epoch 133/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9815\n",
            "Epoch 134/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9817\n",
            "Epoch 135/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9817\n",
            "Epoch 136/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9817\n",
            "Epoch 137/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 5.2651e-10 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9817\n",
            "Epoch 138/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9818\n",
            "Epoch 139/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9818\n",
            "Epoch 140/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9819\n",
            "Epoch 141/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9818\n",
            "Epoch 142/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9671e-10 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9819\n",
            "Epoch 143/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9819\n",
            "Epoch 144/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9819\n",
            "Epoch 145/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2651e-10 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9819\n",
            "Epoch 146/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.2253e-10 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9819\n",
            "Epoch 147/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.9869e-10 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9819\n",
            "Epoch 148/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9819\n",
            "Epoch 149/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9819\n",
            "Epoch 150/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9818\n",
            "Epoch 151/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.3445e-10 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9818\n",
            "Epoch 152/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9819\n",
            "Epoch 153/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9818\n",
            "Epoch 154/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.9869e-10 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9819\n",
            "Epoch 155/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9818\n",
            "Epoch 156/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4240e-10 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9818\n",
            "Epoch 157/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4042e-10 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9818\n",
            "Epoch 158/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9817\n",
            "Epoch 159/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.3048e-10 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9818\n",
            "Epoch 160/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.1856e-10 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9819\n",
            "Epoch 161/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4439e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9818\n",
            "Epoch 162/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.3843e-10 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9817\n",
            "Epoch 163/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5432e-10 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9816\n",
            "Epoch 164/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4240e-10 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9818\n",
            "Epoch 165/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9817\n",
            "Epoch 166/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.5432e-10 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9819\n",
            "Epoch 167/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.6227e-10 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9817\n",
            "Epoch 168/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4638e-10 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9819\n",
            "Epoch 169/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.6227e-10 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9816\n",
            "Epoch 170/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5035e-10 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9814\n",
            "Epoch 171/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.7419e-10 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9815\n",
            "Epoch 172/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.6823e-10 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9817\n",
            "Epoch 173/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.6823e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9816\n",
            "Epoch 174/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.6624e-10 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9817\n",
            "Epoch 175/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9817\n",
            "Epoch 176/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9817\n",
            "Epoch 177/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.8015e-10 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9816\n",
            "Epoch 178/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9817\n",
            "Epoch 179/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 6.1194e-10 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9815\n",
            "Epoch 180/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9817\n",
            "Epoch 181/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.1790e-10 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9814\n",
            "Epoch 182/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0399e-10 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9813\n",
            "Epoch 183/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0598e-10 - accuracy: 1.0000 - val_loss: 0.2710 - val_accuracy: 0.9814\n",
            "Epoch 184/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.7817e-10 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9815\n",
            "Epoch 185/500\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 6.2188e-10 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9816\n",
            "Epoch 186/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.2585e-10 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9815\n",
            "Epoch 187/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.9406e-10 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9813\n",
            "Epoch 188/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.2188e-10 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9812\n",
            "Epoch 189/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3380e-10 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9815\n",
            "Epoch 190/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3181e-10 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9816\n",
            "Epoch 191/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3181e-10 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9816\n",
            "Epoch 192/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3181e-10 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9815\n",
            "Epoch 193/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.6360e-10 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9813\n",
            "Epoch 194/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9812\n",
            "Epoch 195/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4174e-10 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9813\n",
            "Epoch 196/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9811\n",
            "Epoch 197/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5168e-10 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9813\n",
            "Epoch 198/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.7353e-10 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9813\n",
            "Epoch 199/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 6.7751e-10 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9815\n",
            "Epoch 200/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 6.7751e-10 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9812\n",
            "Epoch 201/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.6757e-10 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9812\n",
            "Epoch 202/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.7552e-10 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9812\n",
            "Epoch 203/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.1128e-10 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9813\n",
            "Epoch 204/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0731e-10 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9813\n",
            "Epoch 205/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9812\n",
            "Epoch 206/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.9141e-10 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9813\n",
            "Epoch 207/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0930e-10 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9813\n",
            "Epoch 208/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.2519e-10 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9814\n",
            "Epoch 209/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0532e-10 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9814\n",
            "Epoch 210/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9737e-10 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9817\n",
            "Epoch 211/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.3910e-10 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9816\n",
            "Epoch 212/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 7.3115e-10 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9813\n",
            "Epoch 213/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 7.1128e-10 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9817\n",
            "Epoch 214/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.3512e-10 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9816\n",
            "Epoch 215/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.2916e-10 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9818\n",
            "Epoch 216/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.6095e-10 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9816\n",
            "Epoch 217/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.1401 - val_accuracy: 0.9450\n",
            "Epoch 218/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0517 - accuracy: 0.9936 - val_loss: 0.2445 - val_accuracy: 0.9799\n",
            "Epoch 219/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.2442 - val_accuracy: 0.9808\n",
            "Epoch 220/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.1167e-04 - accuracy: 0.9999 - val_loss: 0.2365 - val_accuracy: 0.9812\n",
            "Epoch 221/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.2913e-04 - accuracy: 0.9999 - val_loss: 0.2447 - val_accuracy: 0.9810\n",
            "Epoch 222/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2553 - val_accuracy: 0.9791\n",
            "Epoch 223/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.2613 - val_accuracy: 0.9789\n",
            "Epoch 224/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.2283 - val_accuracy: 0.9798\n",
            "Epoch 225/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.6918e-04 - accuracy: 0.9998 - val_loss: 0.2240 - val_accuracy: 0.9808\n",
            "Epoch 226/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.5989e-04 - accuracy: 0.9999 - val_loss: 0.2261 - val_accuracy: 0.9809\n",
            "Epoch 227/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 8.0211e-05 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9817\n",
            "Epoch 228/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.9839e-06 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9817\n",
            "Epoch 229/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.9963e-06 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9821\n",
            "Epoch 230/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.2002e-06 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9822\n",
            "Epoch 231/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4014e-06 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9822\n",
            "Epoch 232/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.1941e-06 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9821\n",
            "Epoch 233/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.0532e-06 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9820\n",
            "Epoch 234/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.4810e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9821\n",
            "Epoch 235/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 8.6330e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9821\n",
            "Epoch 236/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 7.9077e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9821\n",
            "Epoch 237/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.2837e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9822\n",
            "Epoch 238/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.7325e-07 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9822\n",
            "Epoch 239/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 6.2346e-07 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9822\n",
            "Epoch 240/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.7766e-07 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9821\n",
            "Epoch 241/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.3562e-07 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9821\n",
            "Epoch 242/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9773e-07 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9821\n",
            "Epoch 243/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 4.6260e-07 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9821\n",
            "Epoch 244/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.2931e-07 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 0.9820\n",
            "Epoch 245/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.9922e-07 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9820\n",
            "Epoch 246/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.7120e-07 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9819\n",
            "Epoch 247/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.4504e-07 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9819\n",
            "Epoch 248/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.2063e-07 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9819\n",
            "Epoch 249/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.9785e-07 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9819\n",
            "Epoch 250/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.7670e-07 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9818\n",
            "Epoch 251/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 2.5707e-07 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9819\n",
            "Epoch 252/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.3862e-07 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9820\n",
            "Epoch 253/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.2113e-07 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9821\n",
            "Epoch 254/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.0550e-07 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9821\n",
            "Epoch 255/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.9057e-07 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9821\n",
            "Epoch 256/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.7685e-07 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9819\n",
            "Epoch 257/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.6393e-07 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9820\n",
            "Epoch 258/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.5170e-07 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9821\n",
            "Epoch 259/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4052e-07 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9821\n",
            "Epoch 260/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.3025e-07 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9821\n",
            "Epoch 261/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.2044e-07 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9820\n",
            "Epoch 262/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.1165e-07 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9819\n",
            "Epoch 263/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.0338e-07 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9819\n",
            "Epoch 264/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 9.5581e-08 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9818\n",
            "Epoch 265/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.8226e-08 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9818\n",
            "Epoch 266/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.1570e-08 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9817\n",
            "Epoch 267/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.5300e-08 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9817\n",
            "Epoch 268/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9644e-08 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9817\n",
            "Epoch 269/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4244e-08 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9819\n",
            "Epoch 270/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.9416e-08 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9819\n",
            "Epoch 271/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.4765e-08 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9819\n",
            "Epoch 272/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0551e-08 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9820\n",
            "Epoch 273/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6633e-08 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9820\n",
            "Epoch 274/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.2997e-08 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9820\n",
            "Epoch 275/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.9619e-08 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9820\n",
            "Epoch 276/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.6520e-08 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9820\n",
            "Epoch 277/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 3.3647e-08 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9819\n",
            "Epoch 278/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 3.0943e-08 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9820\n",
            "Epoch 279/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.8551e-08 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9820\n",
            "Epoch 280/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.6220e-08 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9821\n",
            "Epoch 281/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.4197e-08 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9820\n",
            "Epoch 282/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.2240e-08 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9820\n",
            "Epoch 283/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 2.0413e-08 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9820\n",
            "Epoch 284/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.8710e-08 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9820\n",
            "Epoch 285/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.7295e-08 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9818\n",
            "Epoch 286/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.5873e-08 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9818\n",
            "Epoch 287/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4617e-08 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9817\n",
            "Epoch 288/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.3437e-08 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9818\n",
            "Epoch 289/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.2334e-08 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9817\n",
            "Epoch 290/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.1331e-08 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9817\n",
            "Epoch 291/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.0401e-08 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9818\n",
            "Epoch 292/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.5228e-09 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9819\n",
            "Epoch 293/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.8255e-09 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9819\n",
            "Epoch 294/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.0824e-09 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9820\n",
            "Epoch 295/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.4188e-09 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9819\n",
            "Epoch 296/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.7910e-09 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9820\n",
            "Epoch 297/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.2525e-09 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9820\n",
            "Epoch 298/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.7896e-09 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9820\n",
            "Epoch 299/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.3147e-09 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9822\n",
            "Epoch 300/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8816e-09 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9820\n",
            "Epoch 301/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.4803e-09 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9822\n",
            "Epoch 302/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.1306e-09 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9822\n",
            "Epoch 303/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.8008e-09 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9823\n",
            "Epoch 304/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.4769e-09 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9825\n",
            "Epoch 305/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.2226e-09 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9821\n",
            "Epoch 306/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.0021e-09 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9825\n",
            "Epoch 307/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.7537e-09 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9825\n",
            "Epoch 308/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 2.5690e-09 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9825\n",
            "Epoch 309/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.3782e-09 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9825\n",
            "Epoch 310/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.1974e-09 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9824\n",
            "Epoch 311/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.0444e-09 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9825\n",
            "Epoch 312/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 1.9550e-09 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9822\n",
            "Epoch 313/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.7961e-09 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9825\n",
            "Epoch 314/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.6729e-09 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9825\n",
            "Epoch 315/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.5855e-09 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9825\n",
            "Epoch 316/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 1.4683e-09 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9825\n",
            "Epoch 317/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.3967e-09 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9823\n",
            "Epoch 318/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.3431e-09 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9822\n",
            "Epoch 319/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.2418e-09 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9821\n",
            "Epoch 320/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.1822e-09 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9822\n",
            "Epoch 321/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.1126e-09 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9821\n",
            "Epoch 322/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.0153e-09 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9822\n",
            "Epoch 323/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.6957e-10 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9823\n",
            "Epoch 324/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.3182e-10 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9822\n",
            "Epoch 325/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.8414e-10 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9822\n",
            "Epoch 326/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 8.4639e-10 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9823\n",
            "Epoch 327/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 8.0069e-10 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9821\n",
            "Epoch 328/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 7.5698e-10 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9821\n",
            "Epoch 329/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.5102e-10 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9821\n",
            "Epoch 330/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9340e-10 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9821\n",
            "Epoch 331/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.7155e-10 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9821\n",
            "Epoch 332/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5764e-10 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9821\n",
            "Epoch 333/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 6.1790e-10 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9820\n",
            "Epoch 334/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.9605e-10 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9821\n",
            "Epoch 335/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.9009e-10 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9821\n",
            "Epoch 336/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9822\n",
            "Epoch 337/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5631e-10 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9822\n",
            "Epoch 338/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9820\n",
            "Epoch 339/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.3247e-10 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9820\n",
            "Epoch 340/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.2055e-10 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9819\n",
            "Epoch 341/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9818\n",
            "Epoch 342/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.2253e-10 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9818\n",
            "Epoch 343/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9819\n",
            "Epoch 344/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1856e-10 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9819\n",
            "Epoch 345/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 5.0068e-10 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9820\n",
            "Epoch 346/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 4.9671e-10 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9821\n",
            "Epoch 347/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9821\n",
            "Epoch 348/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8677e-10 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9820\n",
            "Epoch 349/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9821\n",
            "Epoch 350/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9821\n",
            "Epoch 351/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0465e-10 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9821\n",
            "Epoch 352/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.1061e-10 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9821\n",
            "Epoch 353/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9823\n",
            "Epoch 354/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9821\n",
            "Epoch 355/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.6293e-10 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9823\n",
            "Epoch 356/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9823\n",
            "Epoch 357/500\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.7286e-10 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9821\n",
            "Epoch 358/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9822\n",
            "Epoch 359/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9823\n",
            "Epoch 360/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9824\n",
            "Epoch 361/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9823\n",
            "Epoch 362/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9823\n",
            "Epoch 363/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9825\n",
            "Epoch 364/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 4.8280e-10 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9823\n",
            "Epoch 365/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 4.7286e-10 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9824\n",
            "Epoch 366/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9823\n",
            "Epoch 367/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9823\n",
            "Epoch 368/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9822\n",
            "Epoch 369/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.5300e-10 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9823\n",
            "Epoch 370/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9824\n",
            "Epoch 371/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9824\n",
            "Epoch 372/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9824\n",
            "Epoch 373/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9825\n",
            "Epoch 374/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6690e-10 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9825\n",
            "Epoch 375/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9825\n",
            "Epoch 376/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8677e-10 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9824\n",
            "Epoch 377/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9824\n",
            "Epoch 378/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 4.7286e-10 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9822\n",
            "Epoch 379/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9823\n",
            "Epoch 380/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9823\n",
            "Epoch 381/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6690e-10 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9823\n",
            "Epoch 382/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8478e-10 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9823\n",
            "Epoch 383/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9821\n",
            "Epoch 384/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 4.7684e-10 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9822\n",
            "Epoch 385/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9821\n",
            "Epoch 386/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8081e-10 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9823\n",
            "Epoch 387/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.6889e-10 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9823\n",
            "Epoch 388/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9821\n",
            "Epoch 389/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9821\n",
            "Epoch 390/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.8280e-10 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9822\n",
            "Epoch 391/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 4.8876e-10 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9819\n",
            "Epoch 392/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9822\n",
            "Epoch 393/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9821\n",
            "Epoch 394/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9273e-10 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9820\n",
            "Epoch 395/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9671e-10 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9820\n",
            "Epoch 396/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9820\n",
            "Epoch 397/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 4.9472e-10 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 0.9820\n",
            "Epoch 398/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9820\n",
            "Epoch 399/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0267e-10 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9821\n",
            "Epoch 400/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9074e-10 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9819\n",
            "Epoch 401/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0068e-10 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9821\n",
            "Epoch 402/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.9869e-10 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9821\n",
            "Epoch 403/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 4.7882e-10 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9820\n",
            "Epoch 404/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.2452e-10 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9822\n",
            "Epoch 405/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9820\n",
            "Epoch 406/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1260e-10 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9819\n",
            "Epoch 407/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9819\n",
            "Epoch 408/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0863e-10 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9820\n",
            "Epoch 409/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.0664e-10 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9821\n",
            "Epoch 410/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.2253e-10 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9821\n",
            "Epoch 411/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.3843e-10 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9820\n",
            "Epoch 412/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9819\n",
            "Epoch 413/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9821\n",
            "Epoch 414/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.6028e-10 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9822\n",
            "Epoch 415/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1657e-10 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9822\n",
            "Epoch 416/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.1856e-10 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9817\n",
            "Epoch 417/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.1459e-10 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9819\n",
            "Epoch 418/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 5.5432e-10 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9821\n",
            "Epoch 419/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4638e-10 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9817\n",
            "Epoch 420/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.6227e-10 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9821\n",
            "Epoch 421/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5432e-10 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9819\n",
            "Epoch 422/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.4240e-10 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9821\n",
            "Epoch 423/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.5830e-10 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9821\n",
            "Epoch 424/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.7220e-10 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9823\n",
            "Epoch 425/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 5.7618e-10 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9818\n",
            "Epoch 426/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0002e-10 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9821\n",
            "Epoch 427/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.9803e-10 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9820\n",
            "Epoch 428/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0797e-10 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9820\n",
            "Epoch 429/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 5.9406e-10 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9820\n",
            "Epoch 430/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 6.2585e-10 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9820\n",
            "Epoch 431/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.1591e-10 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9822\n",
            "Epoch 432/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3578e-10 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9824\n",
            "Epoch 433/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.3181e-10 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9821\n",
            "Epoch 434/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0995e-10 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9818\n",
            "Epoch 435/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.0002e-10 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9822\n",
            "Epoch 436/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.1989e-10 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9818\n",
            "Epoch 437/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.3976e-10 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9821\n",
            "Epoch 438/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.6360e-10 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9821\n",
            "Epoch 439/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.1790e-10 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9821\n",
            "Epoch 440/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5962e-10 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9820\n",
            "Epoch 441/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.6559e-10 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9823\n",
            "Epoch 442/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4969e-10 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9820\n",
            "Epoch 443/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.7552e-10 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9823\n",
            "Epoch 444/500\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.6559e-10 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9818\n",
            "Epoch 445/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.5764e-10 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9819\n",
            "Epoch 446/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4770e-10 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9819\n",
            "Epoch 447/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.6161e-10 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9819\n",
            "Epoch 448/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.8347e-10 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9821\n",
            "Epoch 449/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 6.4770e-10 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9823\n",
            "Epoch 450/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.7155e-10 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9822\n",
            "Epoch 451/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.4770e-10 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9819\n",
            "Epoch 452/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.6161e-10 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9819\n",
            "Epoch 453/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.7353e-10 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9820\n",
            "Epoch 454/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.1128e-10 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9819\n",
            "Epoch 455/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.5565e-10 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9819\n",
            "Epoch 456/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 6.7155e-10 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9820\n",
            "Epoch 457/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 7.3314e-10 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9822\n",
            "Epoch 458/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9340e-10 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9822\n",
            "Epoch 459/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0135e-10 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9820\n",
            "Epoch 460/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.0333e-10 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9820\n",
            "Epoch 461/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.1724e-10 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9821\n",
            "Epoch 462/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9936e-10 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9821\n",
            "Epoch 463/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 7.0930e-10 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9820\n",
            "Epoch 464/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 7.3512e-10 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9822\n",
            "Epoch 465/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9340e-10 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9821\n",
            "Epoch 466/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.1526e-10 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9821\n",
            "Epoch 467/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 6.9737e-10 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9821\n",
            "Epoch 468/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.5102e-10 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9821\n",
            "Epoch 469/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.1658e-10 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9821\n",
            "Epoch 470/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 7.7685e-10 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9821\n",
            "Epoch 471/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 7.4704e-10 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.9821\n",
            "Epoch 472/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.4903e-10 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9821\n",
            "Epoch 473/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.6493e-10 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9822\n",
            "Epoch 474/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.7089e-10 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9821\n",
            "Epoch 475/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.3049e-10 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9822\n",
            "Epoch 476/500\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 8.9010e-10 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.9820\n",
            "Epoch 477/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 9.1592e-10 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9821\n",
            "Epoch 478/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.3844e-10 - accuracy: 1.0000 - val_loss: 0.3039 - val_accuracy: 0.9820\n",
            "Epoch 479/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.4440e-10 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.9822\n",
            "Epoch 480/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 9.3182e-10 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9818\n",
            "Epoch 481/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.4440e-10 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9820\n",
            "Epoch 482/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.1261e-10 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9821\n",
            "Epoch 483/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 8.1658e-10 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9821\n",
            "Epoch 484/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 8.5831e-10 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9822\n",
            "Epoch 485/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.7818e-10 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9818\n",
            "Epoch 486/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.0530e-09 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9822\n",
            "Epoch 487/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0545 - accuracy: 0.9934 - val_loss: 0.3047 - val_accuracy: 0.9785\n",
            "Epoch 488/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.2979 - val_accuracy: 0.9794\n",
            "Epoch 489/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.2942 - val_accuracy: 0.9804\n",
            "Epoch 490/500\n",
            "235/235 [==============================] - 2s 11ms/step - loss: 4.7878e-04 - accuracy: 0.9998 - val_loss: 0.2782 - val_accuracy: 0.9805\n",
            "Epoch 491/500\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.2631 - val_accuracy: 0.9818\n",
            "Epoch 492/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 3.4997e-04 - accuracy: 0.9999 - val_loss: 0.2609 - val_accuracy: 0.9817\n",
            "Epoch 493/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 2.8106e-06 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9818\n",
            "Epoch 494/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.7666e-06 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9818\n",
            "Epoch 495/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.4254e-06 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9819\n",
            "Epoch 496/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 1.2118e-06 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9819\n",
            "Epoch 497/500\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.0436e-06 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9819\n",
            "Epoch 498/500\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 9.1331e-07 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9820\n",
            "Epoch 499/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 8.0919e-07 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9821\n",
            "Epoch 500/500\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 7.1917e-07 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_features, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPCdwLixiFzb",
        "outputId": "eb7aeb4f-f1fa-4cde-90c8-6cb52a3cf37e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2590442895889282, 0.9821000099182129]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = test_features[0]\n",
        "print(test_labels[0])\n",
        "plt.gray()\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "ypLvQ7e1jPR5",
        "outputId": "ac3896eb-1c29-4273-8de7-e88f871ca393"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7dbe8e1738b0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaqElEQVR4nO3df2xV9f3H8VeL9ILaXiylvb2jQEEFwy8ng9rwYygNtC4GtEtA/QMWAoFdzLDzx7qIKFvSjSWOuCD+s8BMxF+JQCRLMym2hNliqDDCph3tugGBFsVxbylSGP18/yDer1cKeMq9ffdeno/kJPTe8+l9ezzhyWlvT9Occ04AAPSxdOsBAAA3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM3GI9wLd1d3frxIkTyszMVFpamvU4AACPnHPq6OhQMBhUevrVr3P6XYBOnDihgoIC6zEAADfo2LFjGj58+FWf73dfgsvMzLQeAQAQB9f7+zxhAdq4caNGjRqlQYMGqaioSB9//PF3WseX3QAgNVzv7/OEBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUqUS8HAAgGbkEmDZtmguFQtGPL1265ILBoKuqqrru2nA47CSxsbGxsSX5Fg6Hr/n3fdyvgC5cuKDGxkaVlJREH0tPT1dJSYnq6+uv2L+rq0uRSCRmAwCkvrgH6IsvvtClS5eUl5cX83heXp7a2tqu2L+qqkp+vz+68Q44ALg5mL8LrrKyUuFwOLodO3bMeiQAQB+I+88B5eTkaMCAAWpvb495vL29XYFA4Ir9fT6ffD5fvMcAAPRzcb8CysjI0JQpU1RTUxN9rLu7WzU1NSouLo73ywEAklRC7oRQUVGhxYsX6wc/+IGmTZumDRs2qLOzUz/5yU8S8XIAgCSUkAAtXLhQn3/+uV544QW1tbXp3nvvVXV19RVvTAAA3LzSnHPOeohvikQi8vv91mMAAG5QOBxWVlbWVZ83fxccAODmRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ9QC+++KLS0tJitnHjxsX7ZQAASe6WRHzS8ePHa9euXf//Irck5GUAAEksIWW45ZZbFAgEEvGpAQApIiHfAzpy5IiCwaBGjx6tJ554QkePHr3qvl1dXYpEIjEbACD1xT1ARUVF2rJli6qrq7Vp0ya1trZq5syZ6ujo6HH/qqoq+f3+6FZQUBDvkQAA/VCac84l8gXOnDmjkSNH6uWXX9bSpUuveL6rq0tdXV3RjyORCBECgBQQDoeVlZV11ecT/u6AIUOG6O6771Zzc3OPz/t8Pvl8vkSPAQDoZxL+c0Bnz55VS0uL8vPzE/1SAIAkEvcAPf3006qrq9O///1vffTRR3rkkUc0YMAAPfbYY/F+KQBAEov7l+COHz+uxx57TKdPn9awYcM0Y8YMNTQ0aNiwYfF+KQBAEkv4mxC8ikQi8vv91mMAAG7Q9d6EwL3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCf+FdOhbP/7xjz2vWbZsWa9e68SJE57XnD9/3vOaN954w/OatrY2z2skXfUXJwKIP66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLNOeesh/imSCQiv99vPUbS+te//uV5zahRo+I/iLGOjo5erfv73/8e50kQb8ePH/e8Zv369b16rf379/dqHS4Lh8PKysq66vNcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJm6xHgDxtWzZMs9rJk2a1KvX+vTTTz2vueeeezyvue+++zyvmT17tuc1knT//fd7XnPs2DHPawoKCjyv6Uv/+9//PK/5/PPPPa/Jz8/3vKY3jh492qt13Iw0sbgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDPSFFNTU9Mna3qrurq6T17njjvu6NW6e++91/OaxsZGz2umTp3qeU1fOn/+vOc1//znPz2v6c0NbbOzsz2vaWlp8bwGiccVEADABAECAJjwHKA9e/bo4YcfVjAYVFpamrZv3x7zvHNOL7zwgvLz8zV48GCVlJToyJEj8ZoXAJAiPAeos7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b968Xn1NGQCQujy/CaGsrExlZWU9Puec04YNG/T8889r/vz5kqTXX39deXl52r59uxYtWnRj0wIAUkZcvwfU2tqqtrY2lZSURB/z+/0qKipSfX19j2u6uroUiURiNgBA6otrgNra2iRJeXl5MY/n5eVFn/u2qqoq+f3+6FZQUBDPkQAA/ZT5u+AqKysVDoej27Fjx6xHAgD0gbgGKBAISJLa29tjHm9vb48+920+n09ZWVkxGwAg9cU1QIWFhQoEAjE/WR+JRLRv3z4VFxfH86UAAEnO87vgzp49q+bm5ujHra2tOnjwoLKzszVixAitXr1av/71r3XXXXepsLBQa9asUTAY1IIFC+I5NwAgyXkO0P79+/XAAw9EP66oqJAkLV68WFu2bNGzzz6rzs5OLV++XGfOnNGMGTNUXV2tQYMGxW9qAEDSS3POOeshvikSicjv91uPAcCj8vJyz2veeecdz2sOHz7sec03/9HsxZdfftmrdbgsHA5f8/v65u+CAwDcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jAJD6cnNzPa959dVXPa9JT/f+b+B169Z5XsNdrfsnroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBTAFUKhkOc1w4YN87zmv//9r+c1TU1Nntegf+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgRQ2ffr0Xq37xS9+EedJerZgwQLPaw4fPhz/QWCCKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwVS2EMPPdSrdQMHDvS8pqamxvOa+vp6z2uQOrgCAgCYIEAAABOeA7Rnzx49/PDDCgaDSktL0/bt22OeX7JkidLS0mK20tLSeM0LAEgRngPU2dmpyZMna+PGjVfdp7S0VCdPnoxub7755g0NCQBIPZ7fhFBWVqaysrJr7uPz+RQIBHo9FAAg9SXke0C1tbXKzc3V2LFjtXLlSp0+ffqq+3Z1dSkSicRsAIDUF/cAlZaW6vXXX1dNTY1++9vfqq6uTmVlZbp06VKP+1dVVcnv90e3goKCeI8EAOiH4v5zQIsWLYr+eeLEiZo0aZLGjBmj2tpazZkz54r9KysrVVFREf04EokQIQC4CST8bdijR49WTk6Ompube3ze5/MpKysrZgMApL6EB+j48eM6ffq08vPzE/1SAIAk4vlLcGfPno25mmltbdXBgweVnZ2t7OxsvfTSSyovL1cgEFBLS4ueffZZ3XnnnZo3b15cBwcAJDfPAdq/f78eeOCB6Mdff/9m8eLF2rRpkw4dOqQ//elPOnPmjILBoObOnatf/epX8vl88ZsaAJD00pxzznqIb4pEIvL7/dZjAP3O4MGDPa/Zu3dvr15r/Pjxntc8+OCDntd89NFHntcgeYTD4Wt+X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4DEeOaZZzyv+f73v9+r16qurva8hjtbwyuugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFDDwox/9yPOaNWvWeF4TiUQ8r5GkdevW9Wod4AVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCtygoUOHel7zyiuveF4zYMAAz2v+/Oc/e14jSQ0NDb1aB3jBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQLf0JsbflZXV3teU1hY6HlNS0uL5zVr1qzxvAboK1wBAQBMECAAgAlPAaqqqtLUqVOVmZmp3NxcLViwQE1NTTH7nD9/XqFQSEOHDtXtt9+u8vJytbe3x3VoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2Rvd56qmn9P777+vdd99VXV2dTpw4oUcffTTugwMAkpunNyF8+5utW7ZsUW5urhobGzVr1iyFw2H98Y9/1NatW/Xggw9KkjZv3qx77rlHDQ0Nuv/+++M3OQAgqd3Q94DC4bAkKTs7W5LU2NioixcvqqSkJLrPuHHjNGLECNXX1/f4Obq6uhSJRGI2AEDq63WAuru7tXr1ak2fPl0TJkyQJLW1tSkjI0NDhgyJ2TcvL09tbW09fp6qqir5/f7oVlBQ0NuRAABJpNcBCoVCOnz4sN56660bGqCyslLhcDi6HTt27IY+HwAgOfTqB1FXrVqlnTt3as+ePRo+fHj08UAgoAsXLujMmTMxV0Ht7e0KBAI9fi6fzyefz9ebMQAASczTFZBzTqtWrdK2bdu0e/fuK36ae8qUKRo4cKBqamqijzU1Neno0aMqLi6Oz8QAgJTg6QooFApp69at2rFjhzIzM6Pf1/H7/Ro8eLD8fr+WLl2qiooKZWdnKysrS08++aSKi4t5BxwAIIanAG3atEmSNHv27JjHN2/erCVLlkiSfv/73ys9PV3l5eXq6urSvHnz9Oqrr8ZlWABA6khzzjnrIb4pEonI7/dbj4Gb1N133+15zWeffZaASa40f/58z2vef//9BEwCfDfhcFhZWVlXfZ57wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEr34jKtDfjRw5slfr/vKXv8R5kp4988wzntfs3LkzAZMAdrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSpKTly5f3at2IESPiPEnP6urqPK9xziVgEsAOV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRop+b8aMGZ7XPPnkkwmYBEA8cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTo92bOnOl5ze23356ASXrW0tLiec3Zs2cTMAmQXLgCAgCYIEAAABOeAlRVVaWpU6cqMzNTubm5WrBggZqammL2mT17ttLS0mK2FStWxHVoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2xuy3bNkynTx5MrqtX78+rkMDAJKfpzchVFdXx3y8ZcsW5ebmqrGxUbNmzYo+fuuttyoQCMRnQgBASrqh7wGFw2FJUnZ2dszjb7zxhnJycjRhwgRVVlbq3LlzV/0cXV1dikQiMRsAIPX1+m3Y3d3dWr16taZPn64JEyZEH3/88cc1cuRIBYNBHTp0SM8995yampr03nvv9fh5qqqq9NJLL/V2DABAkup1gEKhkA4fPqy9e/fGPL58+fLonydOnKj8/HzNmTNHLS0tGjNmzBWfp7KyUhUVFdGPI5GICgoKejsWACBJ9CpAq1at0s6dO7Vnzx4NHz78mvsWFRVJkpqbm3sMkM/nk8/n680YAIAk5ilAzjk9+eST2rZtm2pra1VYWHjdNQcPHpQk5efn92pAAEBq8hSgUCikrVu3aseOHcrMzFRbW5skye/3a/DgwWppadHWrVv10EMPaejQoTp06JCeeuopzZo1S5MmTUrIfwAAIDl5CtCmTZskXf5h02/avHmzlixZooyMDO3atUsbNmxQZ2enCgoKVF5erueffz5uAwMAUoPnL8FdS0FBgerq6m5oIADAzYG7YQPf8Le//c3zmjlz5nhe8+WXX3peA6QabkYKADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIc9e7xXUfi0Qi8vv91mMAAG5QOBxWVlbWVZ/nCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJfhegfnZrOgBAL13v7/N+F6COjg7rEQAAcXC9v8/73d2wu7u7deLECWVmZiotLS3muUgkooKCAh07duyad1hNdRyHyzgOl3EcLuM4XNYfjoNzTh0dHQoGg0pPv/p1zi19ONN3kp6eruHDh19zn6ysrJv6BPsax+EyjsNlHIfLOA6XWR+H7/Jrdfrdl+AAADcHAgQAMJFUAfL5fFq7dq18Pp/1KKY4DpdxHC7jOFzGcbgsmY5Dv3sTAgDg5pBUV0AAgNRBgAAAJggQAMAEAQIAmEiaAG3cuFGjRo3SoEGDVFRUpI8//th6pD734osvKi0tLWYbN26c9VgJt2fPHj388MMKBoNKS0vT9u3bY553zumFF15Qfn6+Bg8erJKSEh05csRm2AS63nFYsmTJFedHaWmpzbAJUlVVpalTpyozM1O5ublasGCBmpqaYvY5f/68QqGQhg4dqttvv13l5eVqb283mjgxvstxmD179hXnw4oVK4wm7llSBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUKevR+tz48eN18uTJ6LZ3717rkRKus7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b948nT9/vo8nTazrHQdJKi0tjTk/3nzzzT6cMPHq6uoUCoXU0NCgDz74QBcvXtTcuXPV2dkZ3eepp57S+++/r3fffVd1dXU6ceKEHn30UcOp4++7HAdJWrZsWcz5sH79eqOJr8IlgWnTprlQKBT9+NKlSy4YDLqqqirDqfre2rVr3eTJk63HMCXJbdu2Lfpxd3e3CwQC7ne/+130sTNnzjifz+fefPNNgwn7xrePg3POLV682M2fP99kHiunTp1yklxdXZ1z7vL/+4EDB7p33303us+nn37qJLn6+nqrMRPu28fBOed++MMfup/97Gd2Q30H/f4K6MKFC2psbFRJSUn0sfT0dJWUlKi+vt5wMhtHjhxRMBjU6NGj9cQTT+jo0aPWI5lqbW1VW1tbzPnh9/tVVFR0U54ftbW1ys3N1dixY7Vy5UqdPn3aeqSECofDkqTs7GxJUmNjoy5evBhzPowbN04jRoxI6fPh28fha2+88YZycnI0YcIEVVZW6ty5cxbjXVW/uxnpt33xxRe6dOmS8vLyYh7Py8vTZ599ZjSVjaKiIm3ZskVjx47VyZMn9dJLL2nmzJk6fPiwMjMzrccz0dbWJkk9nh9fP3ezKC0t1aOPPqrCwkK1tLTol7/8pcrKylRfX68BAwZYjxd33d3dWr16taZPn64JEyZIunw+ZGRkaMiQITH7pvL50NNxkKTHH39cI0eOVDAY1KFDh/Tcc8+pqalJ7733nuG0sfp9gPD/ysrKon+eNGmSioqKNHLkSL3zzjtaunSp4WToDxYtWhT988SJEzVp0iSNGTNGtbW1mjNnjuFkiREKhXT48OGb4vug13K147B8+fLonydOnKj8/HzNmTNHLS0tGjNmTF+P2aN+/yW4nJwcDRgw4Ip3sbS3tysQCBhN1T8MGTJEd999t5qbm61HMfP1OcD5caXRo0crJycnJc+PVatWaefOnfrwww9jfn1LIBDQhQsXdObMmZj9U/V8uNpx6ElRUZEk9avzod8HKCMjQ1OmTFFNTU30se7ubtXU1Ki4uNhwMntnz55VS0uL8vPzrUcxU1hYqEAgEHN+RCIR7du376Y/P44fP67Tp0+n1PnhnNOqVau0bds27d69W4WFhTHPT5kyRQMHDow5H5qamnT06NGUOh+udxx6cvDgQUnqX+eD9bsgvou33nrL+Xw+t2XLFvePf/zDLV++3A0ZMsS1tbVZj9anfv7zn7va2lrX2trq/vrXv7qSkhKXk5PjTp06ZT1aQnV0dLgDBw64AwcOOEnu5ZdfdgcOHHD/+c9/nHPO/eY3v3FDhgxxO3bscIcOHXLz5893hYWF7quvvjKePL6udRw6Ojrc008/7err611ra6vbtWuXu++++9xdd93lzp8/bz163KxcudL5/X5XW1vrTp48Gd3OnTsX3WfFihVuxIgRbvfu3W7//v2uuLjYFRcXG04df9c7Ds3NzW7dunVu//79rrW11e3YscONHj3azZo1y3jyWEkRIOec+8Mf/uBGjBjhMjIy3LRp01xDQ4P1SH1u4cKFLj8/32VkZLjvfe97buHCha65udl6rIT78MMPnaQrtsWLFzvnLr8Ve82aNS4vL8/5fD43Z84c19TUZDt0AlzrOJw7d87NnTvXDRs2zA0cONCNHDnSLVu2LOX+kdbTf78kt3nz5ug+X331lfvpT3/q7rjjDnfrrbe6Rx55xJ08edJu6AS43nE4evSomzVrlsvOznY+n8/deeed7plnnnHhcNh28G/h1zEAAEz0++8BAQBSEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABg4v8AjVqFRqQZEfIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.reshape(img, (-1, 784))\n",
        "test_pred = model.predict(test_data)\n",
        "test_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxj00d-2jmom",
        "outputId": "b6ecad4a-972f-4c00-d1eb-65f60d78f2c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 103ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.6988466e-32, 0.0000000e+00, 3.5397411e-37, 2.9860317e-36,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
              "        0.0000000e+00, 9.3216835e-27]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4K8YeCiYkEsg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}