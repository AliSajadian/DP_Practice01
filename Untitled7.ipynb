{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPumeATxi8nyv8NPquMiJJ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliSajadian/DP_Practice01/blob/master/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hM5PKfiO9kH",
        "outputId": "916246ee-fbfb-49ae-b38b-e1aafa4ff57c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "lL14bjoaPLOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1).astype(float)/255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1).astype(float)/255"
      ],
      "metadata": {
        "id": "EOTe-ii7PKHV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition"
      ],
      "metadata": {
        "id": "vrak5G6oPb1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(keras.layers.AveragePooling2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=(2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=128, activation='relu'))\n",
        "model.add(keras.layers.Dense(units=10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "u-4pPfqJPVlx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "lUyI4eLWPXza"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXGHxIwPWueK",
        "outputId": "1b94d097-ffff-4432-bcd9-ee46f09b1379"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 13, 13, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 11, 11, 64)        73792     \n",
            "                                                                 \n",
            " average_pooling2d_3 (Avera  (None, 5, 5, 64)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 32)          18464     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 1, 1, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               8448      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 136170 (531.91 KB)\n",
            "Trainable params: 136170 (531.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_train, y_train, batch_size=256, epochs=300, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JBxGwGjXWsA",
        "outputId": "7f4f01c2-66c6-4145-ba71-e694b55a37f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "235/235 [==============================] - 9s 15ms/step - loss: 0.4932 - accuracy: 0.8501 - val_loss: 0.1477 - val_accuracy: 0.9537\n",
            "Epoch 2/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.1377 - accuracy: 0.9591 - val_loss: 0.0946 - val_accuracy: 0.9708\n",
            "Epoch 3/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1006 - accuracy: 0.9693 - val_loss: 0.0902 - val_accuracy: 0.9732\n",
            "Epoch 4/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0810 - accuracy: 0.9754 - val_loss: 0.0627 - val_accuracy: 0.9807\n",
            "Epoch 5/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0651 - accuracy: 0.9799 - val_loss: 0.0665 - val_accuracy: 0.9800\n",
            "Epoch 6/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0587 - accuracy: 0.9821 - val_loss: 0.0580 - val_accuracy: 0.9830\n",
            "Epoch 7/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0500 - accuracy: 0.9848 - val_loss: 0.0529 - val_accuracy: 0.9845\n",
            "Epoch 8/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0464 - accuracy: 0.9856 - val_loss: 0.0461 - val_accuracy: 0.9866\n",
            "Epoch 9/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0465 - val_accuracy: 0.9872\n",
            "Epoch 10/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 0.0489 - val_accuracy: 0.9843\n",
            "Epoch 11/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0501 - val_accuracy: 0.9866\n",
            "Epoch 12/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0423 - val_accuracy: 0.9873\n",
            "Epoch 13/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.0460 - val_accuracy: 0.9871\n",
            "Epoch 14/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
            "Epoch 15/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0523 - val_accuracy: 0.9865\n",
            "Epoch 16/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0500 - val_accuracy: 0.9867\n",
            "Epoch 17/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0477 - val_accuracy: 0.9873\n",
            "Epoch 18/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0445 - val_accuracy: 0.9888\n",
            "Epoch 19/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0489 - val_accuracy: 0.9872\n",
            "Epoch 20/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0562 - val_accuracy: 0.9858\n",
            "Epoch 21/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0529 - val_accuracy: 0.9884\n",
            "Epoch 22/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0517 - val_accuracy: 0.9878\n",
            "Epoch 23/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0516 - val_accuracy: 0.9876\n",
            "Epoch 24/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0564 - val_accuracy: 0.9870\n",
            "Epoch 25/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0499 - val_accuracy: 0.9884\n",
            "Epoch 26/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
            "Epoch 27/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0588 - val_accuracy: 0.9855\n",
            "Epoch 28/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0480 - val_accuracy: 0.9892\n",
            "Epoch 29/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0509 - val_accuracy: 0.9878\n",
            "Epoch 30/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0509 - val_accuracy: 0.9887\n",
            "Epoch 31/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0599 - val_accuracy: 0.9879\n",
            "Epoch 32/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0578 - val_accuracy: 0.9875\n",
            "Epoch 33/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0617 - val_accuracy: 0.9880\n",
            "Epoch 34/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0590 - val_accuracy: 0.9882\n",
            "Epoch 35/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.0531 - val_accuracy: 0.9880\n",
            "Epoch 36/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0564 - val_accuracy: 0.9882\n",
            "Epoch 37/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0634 - val_accuracy: 0.9870\n",
            "Epoch 38/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0635 - val_accuracy: 0.9881\n",
            "Epoch 39/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0674 - val_accuracy: 0.9866\n",
            "Epoch 40/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0673 - val_accuracy: 0.9860\n",
            "Epoch 41/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0540 - val_accuracy: 0.9894\n",
            "Epoch 42/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0738 - val_accuracy: 0.9871\n",
            "Epoch 43/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0581 - val_accuracy: 0.9900\n",
            "Epoch 44/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0608 - val_accuracy: 0.9882\n",
            "Epoch 45/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0625 - val_accuracy: 0.9886\n",
            "Epoch 46/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0774 - val_accuracy: 0.9865\n",
            "Epoch 47/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0755 - val_accuracy: 0.9876\n",
            "Epoch 48/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0715 - val_accuracy: 0.9887\n",
            "Epoch 49/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0654 - val_accuracy: 0.9890\n",
            "Epoch 50/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0678 - val_accuracy: 0.9872\n",
            "Epoch 51/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0612 - val_accuracy: 0.9892\n",
            "Epoch 52/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0759 - val_accuracy: 0.9875\n",
            "Epoch 53/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0714 - val_accuracy: 0.9879\n",
            "Epoch 54/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0720 - val_accuracy: 0.9868\n",
            "Epoch 55/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0737 - val_accuracy: 0.9885\n",
            "Epoch 56/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0698 - val_accuracy: 0.9881\n",
            "Epoch 57/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0682 - val_accuracy: 0.9891\n",
            "Epoch 58/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0857 - val_accuracy: 0.9858\n",
            "Epoch 59/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0701 - val_accuracy: 0.9881\n",
            "Epoch 60/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0785 - val_accuracy: 0.9894\n",
            "Epoch 61/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0759 - val_accuracy: 0.9890\n",
            "Epoch 62/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0726 - val_accuracy: 0.9884\n",
            "Epoch 63/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0785 - val_accuracy: 0.9881\n",
            "Epoch 64/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.0621e-04 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9901\n",
            "Epoch 65/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.8901e-05 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9903\n",
            "Epoch 66/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.1681e-05 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9902\n",
            "Epoch 67/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5135e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9902\n",
            "Epoch 68/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2301e-05 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9902\n",
            "Epoch 69/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.8689e-06 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9902\n",
            "Epoch 70/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 8.1760e-06 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9902\n",
            "Epoch 71/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.9300e-06 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9902\n",
            "Epoch 72/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.6713e-06 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9901\n",
            "Epoch 73/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.8183e-06 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9900\n",
            "Epoch 74/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.1554e-06 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9900\n",
            "Epoch 75/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.5167e-06 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9900\n",
            "Epoch 76/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.0149e-06 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9900\n",
            "Epoch 77/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.5747e-06 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9900\n",
            "Epoch 78/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.2608e-06 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9900\n",
            "Epoch 79/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.9569e-06 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9899\n",
            "Epoch 80/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.7027e-06 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9899\n",
            "Epoch 81/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4917e-06 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9899\n",
            "Epoch 82/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.3067e-06 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9899\n",
            "Epoch 83/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.1442e-06 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9899\n",
            "Epoch 84/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.9542e-07 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9900\n",
            "Epoch 85/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.6926e-07 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9900\n",
            "Epoch 86/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 7.6230e-07 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9899\n",
            "Epoch 87/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.7216e-07 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9901\n",
            "Epoch 88/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.8328e-07 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9902\n",
            "Epoch 89/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.1861e-07 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9901\n",
            "Epoch 90/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.5815e-07 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9900\n",
            "Epoch 91/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.9846e-07 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9902\n",
            "Epoch 92/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.5594e-07 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9901\n",
            "Epoch 93/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.1102e-07 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9901\n",
            "Epoch 94/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.7337e-07 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9901\n",
            "Epoch 95/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.3975e-07 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9902\n",
            "Epoch 96/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.1537e-07 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9903\n",
            "Epoch 97/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.8878e-07 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9901\n",
            "Epoch 98/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.6536e-07 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9903\n",
            "Epoch 99/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.4426e-07 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9901\n",
            "Epoch 100/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.2882e-07 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9902\n",
            "Epoch 101/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.1341e-07 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9904\n",
            "Epoch 102/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0064e-07 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9903\n",
            "Epoch 103/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 8.9602e-08 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9903\n",
            "Epoch 104/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.7398e-08 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9903\n",
            "Epoch 105/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 6.9435e-08 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9903\n",
            "Epoch 106/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 6.1170e-08 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9903\n",
            "Epoch 107/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.3596e-08 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9902\n",
            "Epoch 108/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.8128e-08 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9904\n",
            "Epoch 109/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.2315e-08 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9904\n",
            "Epoch 110/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.7440e-08 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9904\n",
            "Epoch 111/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.3192e-08 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9904\n",
            "Epoch 112/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.9600e-08 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9904\n",
            "Epoch 113/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.6172e-08 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9905\n",
            "Epoch 114/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.3677e-08 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9904\n",
            "Epoch 115/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.0446e-08 - accuracy: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9905\n",
            "Epoch 116/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.8322e-08 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9905\n",
            "Epoch 117/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.6373e-08 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9906\n",
            "Epoch 118/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.4536e-08 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9905\n",
            "Epoch 119/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2888e-08 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9906\n",
            "Epoch 120/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.1661e-08 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9906\n",
            "Epoch 121/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.0115e-08 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9908\n",
            "Epoch 122/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.1573e-09 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9907\n",
            "Epoch 123/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.0943e-09 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9908\n",
            "Epoch 124/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 7.4029e-09 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9908\n",
            "Epoch 125/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.4333e-09 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9909\n",
            "Epoch 126/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.8671e-09 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9908\n",
            "Epoch 127/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.1041e-09 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9907\n",
            "Epoch 128/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.6094e-09 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9907\n",
            "Epoch 129/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.2319e-09 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9908\n",
            "Epoch 130/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.7809e-09 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9908\n",
            "Epoch 131/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.3696e-09 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9908\n",
            "Epoch 132/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 3.0041e-09 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9908\n",
            "Epoch 133/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.7339e-09 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9908\n",
            "Epoch 134/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 2.4418e-09 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9908\n",
            "Epoch 135/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.2570e-09 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9907\n",
            "Epoch 136/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.0087e-09 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9907\n",
            "Epoch 137/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8497e-09 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9908\n",
            "Epoch 138/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.6669e-09 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9907\n",
            "Epoch 139/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5060e-09 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9907\n",
            "Epoch 140/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.3848e-09 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9907\n",
            "Epoch 141/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2418e-09 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 142/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.0967e-09 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9908\n",
            "Epoch 143/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0411e-09 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9906\n",
            "Epoch 144/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 9.3381e-10 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9907\n",
            "Epoch 145/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.7420e-10 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9906\n",
            "Epoch 146/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.8678e-10 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9907\n",
            "Epoch 147/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.1128e-10 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9906\n",
            "Epoch 148/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.6360e-10 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9907\n",
            "Epoch 149/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.9207e-10 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9906\n",
            "Epoch 150/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.7817e-10 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9907\n",
            "Epoch 151/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.4836e-10 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9906\n",
            "Epoch 152/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.0267e-10 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9905\n",
            "Epoch 153/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.6094e-10 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9906\n",
            "Epoch 154/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.2915e-10 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9906\n",
            "Epoch 155/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.1723e-10 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9907\n",
            "Epoch 156/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.0332e-10 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9907\n",
            "Epoch 157/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.6359e-10 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9906\n",
            "Epoch 158/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.2783e-10 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9906\n",
            "Epoch 159/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.3577e-10 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9908\n",
            "Epoch 160/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 3.2187e-10 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9906\n",
            "Epoch 161/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.0200e-10 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9906\n",
            "Epoch 162/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 2.7815e-10 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9908\n",
            "Epoch 163/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.6623e-10 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9906\n",
            "Epoch 164/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.7617e-10 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9906\n",
            "Epoch 165/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.5034e-10 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9908\n",
            "Epoch 166/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.4041e-10 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9906\n",
            "Epoch 167/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.5233e-10 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9907\n",
            "Epoch 168/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.1458e-10 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9908\n",
            "Epoch 169/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.3643e-10 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9908\n",
            "Epoch 170/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9907\n",
            "Epoch 171/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 2.1855e-10 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9908\n",
            "Epoch 172/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.1060e-10 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9908\n",
            "Epoch 173/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.2848e-10 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9908\n",
            "Epoch 174/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.9471e-10 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9908\n",
            "Epoch 175/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 2.0862e-10 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9906\n",
            "Epoch 176/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.1060e-10 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9908\n",
            "Epoch 177/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.1259e-10 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9908\n",
            "Epoch 178/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.0266e-10 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9908\n",
            "Epoch 179/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.8875e-10 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9908\n",
            "Epoch 180/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9908\n",
            "Epoch 181/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8875e-10 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9908\n",
            "Epoch 182/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.9272e-10 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9908\n",
            "Epoch 183/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.7484e-10 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9908\n",
            "Epoch 184/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.9272e-10 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9908\n",
            "Epoch 185/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8080e-10 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9908\n",
            "Epoch 186/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8080e-10 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9907\n",
            "Epoch 187/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.7285e-10 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9907\n",
            "Epoch 188/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8080e-10 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9907\n",
            "Epoch 189/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5696e-10 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9908\n",
            "Epoch 190/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9908\n",
            "Epoch 191/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.8279e-10 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9908\n",
            "Epoch 192/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9907\n",
            "Epoch 193/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9908\n",
            "Epoch 194/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6888e-10 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9907\n",
            "Epoch 195/300\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 1.5299e-10 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9907\n",
            "Epoch 196/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 1.7683e-10 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9908\n",
            "Epoch 197/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5895e-10 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9909\n",
            "Epoch 198/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.6093e-10 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9907\n",
            "Epoch 199/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6689e-10 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9907\n",
            "Epoch 200/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5696e-10 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9909\n",
            "Epoch 201/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6491e-10 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9908\n",
            "Epoch 202/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.5696e-10 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9908\n",
            "Epoch 203/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3113e-10 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9910\n",
            "Epoch 204/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6491e-10 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9907\n",
            "Epoch 205/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5497e-10 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9909\n",
            "Epoch 206/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.3113e-10 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9909\n",
            "Epoch 207/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6093e-10 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9908\n",
            "Epoch 208/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3908e-10 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9908\n",
            "Epoch 209/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.6093e-10 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9909\n",
            "Epoch 210/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.5299e-10 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9908\n",
            "Epoch 211/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5100e-10 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9909\n",
            "Epoch 212/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3113e-10 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9908\n",
            "Epoch 213/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.4901e-10 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9908\n",
            "Epoch 214/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.5100e-10 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9907\n",
            "Epoch 215/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3709e-10 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9908\n",
            "Epoch 216/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.4305e-10 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9907\n",
            "Epoch 217/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3709e-10 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9907\n",
            "Epoch 218/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.3709e-10 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9907\n",
            "Epoch 219/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.2517e-10 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 220/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2914e-10 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9907\n",
            "Epoch 221/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.5100e-10 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9907\n",
            "Epoch 222/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.3113e-10 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 223/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3510e-10 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9907\n",
            "Epoch 224/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3312e-10 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 225/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3908e-10 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 226/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.1325e-10 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 227/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2318e-10 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 228/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 229/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.3709e-10 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 230/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.0530e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9907\n",
            "Epoch 231/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2318e-10 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 232/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.1722e-10 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9907\n",
            "Epoch 233/300\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.2120e-10 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 234/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9907\n",
            "Epoch 235/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.5367e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 236/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.2517e-10 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9907\n",
            "Epoch 237/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.1126e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9907\n",
            "Epoch 238/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.1126e-10 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 239/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0331e-10 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9907\n",
            "Epoch 240/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.1722e-10 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9907\n",
            "Epoch 241/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0530e-10 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9907\n",
            "Epoch 242/300\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 1.0331e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9907\n",
            "Epoch 243/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.5367e-11 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9907\n",
            "Epoch 244/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.1921e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9908\n",
            "Epoch 245/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.0133e-10 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9907\n",
            "Epoch 246/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.0331e-10 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 247/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.5433e-11 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9907\n",
            "Epoch 248/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 1.1524e-10 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9908\n",
            "Epoch 249/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 9.1394e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 250/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 251/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.3381e-11 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9909\n",
            "Epoch 252/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 9.3381e-11 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9908\n",
            "Epoch 253/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 8.3446e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9908\n",
            "Epoch 254/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 1.0133e-10 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9908\n",
            "Epoch 255/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.5433e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9908\n",
            "Epoch 256/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.5433e-11 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9908\n",
            "Epoch 257/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 7.5499e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9908\n",
            "Epoch 258/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 8.1460e-11 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9908\n",
            "Epoch 259/300\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 9.5367e-11 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9908\n",
            "Epoch 260/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 8.3446e-11 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9908\n",
            "Epoch 261/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 7.1526e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 262/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9907\n",
            "Epoch 263/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.7486e-11 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9907\n",
            "Epoch 264/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9907\n",
            "Epoch 265/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 266/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.3578e-11 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9907\n",
            "Epoch 267/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 7.9473e-11 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9907\n",
            "Epoch 268/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.1591e-11 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9907\n",
            "Epoch 269/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 6.9539e-11 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9907\n",
            "Epoch 270/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.5631e-11 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 271/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.5565e-11 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9907\n",
            "Epoch 272/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.7618e-11 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9907\n",
            "Epoch 273/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.7618e-11 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9907\n",
            "Epoch 274/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.9539e-11 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9907\n",
            "Epoch 275/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.5565e-11 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9907\n",
            "Epoch 276/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.9605e-11 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9907\n",
            "Epoch 277/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.3644e-11 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9907\n",
            "Epoch 278/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9907\n",
            "Epoch 279/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 5.3644e-11 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9907\n",
            "Epoch 280/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 4.9671e-11 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9907\n",
            "Epoch 281/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 5.3644e-11 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9907\n",
            "Epoch 282/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.3710e-11 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9907\n",
            "Epoch 283/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.7684e-11 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9907\n",
            "Epoch 284/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 5.7618e-11 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9907\n",
            "Epoch 285/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.5697e-11 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9907\n",
            "Epoch 286/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.7750e-11 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9907\n",
            "Epoch 287/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9907\n",
            "Epoch 288/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 4.5697e-11 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9907\n",
            "Epoch 289/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 4.7684e-11 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9907\n",
            "Epoch 290/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9907\n",
            "Epoch 291/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.9736e-11 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9907\n",
            "Epoch 292/300\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 3.5763e-11 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9907\n",
            "Epoch 293/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 2.5829e-11 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9907\n",
            "Epoch 294/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.7750e-11 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9907\n",
            "Epoch 295/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.7750e-11 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9907\n",
            "Epoch 296/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.9802e-11 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9907\n",
            "Epoch 297/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.3776e-11 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9907\n",
            "Epoch 298/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.5763e-11 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9907\n",
            "Epoch 299/300\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 2.3842e-11 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9907\n",
            "Epoch 300/300\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 3.3776e-11 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist.history['accuracy'], color='red')\n",
        "plt.plot(hist.history['val_accuracy'], color='blue')\n",
        "plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "KVhvQXOYhBZI",
        "outputId": "ee6abac9-40c5-4245-b1e4-0dec220876ad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}